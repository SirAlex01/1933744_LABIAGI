{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InYkpqTZmqjn",
        "outputId": "a71d347c-0ec0-44e7-ba19-349c3938c030"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['aguasclaras', 'bercy', 'bordeaux', 'nantes', 'paris', 'rennes', 'saclay_e', 'abudhabi', 'cupertino', 'pisa', 'beihai', 'hongkong', 'beirut', 'mumbai']\n",
            "['brasilia', 'montpellier', 'norcia', 'rio', 'saclay_w', 'valencia', 'dubai', 'lasvegas', 'milano', 'chongqing']\n",
            "['aguasclaras', 'bercy', 'bordeaux', 'nantes', 'paris', 'rennes', 'saclay_e', 'abudhabi', 'cupertino', 'pisa', 'beihai', 'hongkong', 'beirut', 'mumbai', 'brasilia', 'montpellier', 'norcia', 'rio', 'saclay_w', 'valencia', 'dubai', 'lasvegas', 'milano', 'chongqing']\n"
          ]
        }
      ],
      "source": [
        "#Apertura dei dati da Google Drive\n",
        "#Caricamento dei file testuali per navigare nelle cartelle e prendere le immagini\n",
        "file=open(\"./drive/MyDrive/OSCD_dataset/OSCD_dataset_images/train.txt\", \"r\")\n",
        "content = file.read()\n",
        "train_set = content.strip().split(\",\")\n",
        "print(train_set)\n",
        "file.close()\n",
        "\n",
        "file=open(\"./drive/MyDrive/OSCD_dataset/OSCD_dataset_images/test.txt\", \"r\")\n",
        "content = file.read()\n",
        "test_set = content.strip().split(\",\")\n",
        "print(test_set)\n",
        "file.close()\n",
        "\n",
        "\n",
        "file=open(\"./drive/MyDrive/OSCD_dataset/OSCD_dataset_images/all.txt\", \"r\")\n",
        "content = file.read()\n",
        "all_locs = content.strip().split(\",\")\n",
        "print(all_locs)\n",
        "file.close()\n",
        "\n",
        "channels = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B10', 'B11', 'B12']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C74Niwmz3oc8",
        "outputId": "cefdde88-128b-4014-9b61-81e8580c1ebf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading: aguasclaras\n",
            "loading: bercy\n",
            "loading: bordeaux\n",
            "loading: nantes\n",
            "loading: paris\n",
            "loading: rennes\n",
            "loading: saclay_e\n",
            "loading: abudhabi\n",
            "loading: cupertino\n",
            "loading: pisa\n",
            "loading: beihai\n",
            "loading: hongkong\n",
            "loading: beirut\n",
            "loading: mumbai\n",
            "loading: brasilia\n",
            "loading: montpellier\n",
            "loading: norcia\n",
            "loading: rio\n",
            "loading: saclay_w\n",
            "loading: valencia\n",
            "loading: dubai\n",
            "loading: lasvegas\n",
            "loading: milano\n",
            "loading: chongqing\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as TF\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from math import floor, ceil, sqrt, exp\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "class RandomNoise():\n",
        "  def __call__(self,sample):\n",
        "    I1, I2, label = sample['I1'], sample['I2'], sample['label']\n",
        "    # Genera rumore salt and pepper\n",
        "    prob = 0.1  # ProbabilitÃ  di avere pixel rumorosi\n",
        "    noise = np.random.choice([0, 1], size=I1.shape[1:], p=[1 - prob, prob])\n",
        "    \n",
        "    # Applica il rumore salt and pepper all'immagine\n",
        "    I1 = torch.from_numpy((I1.numpy() * (1 - noise) + noise))\n",
        "    I2 = torch.from_numpy((I2.numpy() * (1 - noise) + noise))\n",
        "    return {'I1': I1, 'I2': I2, 'label': label}\n",
        "\n",
        "class RandomFlip():\n",
        "    \"\"\"Flip randomly the images in a sample.\"\"\"\n",
        "\n",
        "#     def __init__(self):\n",
        "#         return\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        I1, I2, label = sample['I1'], sample['I2'], sample['label']\n",
        "        \n",
        "        if random.random() > 0.5:\n",
        "            I1 =  I1.numpy()[:,:,::-1].copy()\n",
        "            I1 = torch.from_numpy(I1)\n",
        "            I2 =  I2.numpy()[:,:,::-1].copy()\n",
        "            I2 = torch.from_numpy(I2)\n",
        "            label =  label.numpy()[:,::-1].copy()\n",
        "            label = torch.from_numpy(label)\n",
        "\n",
        "        return {'I1': I1, 'I2': I2, 'label': label}\n",
        "\n",
        "\n",
        "\n",
        "class RandomRot():\n",
        "    \"\"\"Rotate randomly the images in a sample.\"\"\"\n",
        "\n",
        "#     def __init__(self):\n",
        "#         return\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        I1, I2, label = sample['I1'], sample['I2'], sample['label']\n",
        "        \n",
        "        n = random.randint(0, 3)\n",
        "        if n:\n",
        "            I1 =  sample['I1'].numpy()\n",
        "            I1 = np.rot90(I1, n, axes=(1, 2)).copy()\n",
        "            I1 = torch.from_numpy(I1)\n",
        "            I2 =  sample['I2'].numpy()\n",
        "            I2 = np.rot90(I2, n, axes=(1, 2)).copy()\n",
        "            I2 = torch.from_numpy(I2)\n",
        "            label =  sample['label'].numpy()\n",
        "            label = np.rot90(label, n, axes=(0, 1)).copy()\n",
        "            label = torch.from_numpy(label)\n",
        "\n",
        "        return {'I1': I1, 'I2': I2, 'label': label}\n",
        "\n",
        "\n",
        "transform=transforms.Compose([\n",
        "    # your code here\n",
        "    RandomFlip(),\n",
        "    RandomRot(),\n",
        "    RandomNoise()\n",
        "])\n",
        "\n",
        "\n",
        "#Inizilizzazione del dataset\n",
        "class OSCD_dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, train=True, normalize=True, transform=None, patch_side = 96, stride = None):\n",
        "        self.train=train\n",
        "        self.transform=transform\n",
        "        self.normalize=normalize\n",
        "        self.patch_side=patch_side\n",
        "        self.stride=1\n",
        "        if stride:\n",
        "          self.stride=stride\n",
        "        #parametro utilizzato da quelli del paper per\n",
        "        #aumentare il peso dei changed pixel.\n",
        "        #potrebbe essere utile farne il tuning (?)\n",
        "       \n",
        "        #self.CIBW=10\n",
        "       \n",
        "        #Carica i dati dai file\n",
        "        self.load_data()\n",
        "\n",
        "    def __len__(self):\n",
        "        # Restituisci la lunghezza del dataset\n",
        "        return self.n_patches\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        current_patch_coords = self.patch_coords[idx]\n",
        "        loc = current_patch_coords[0]\n",
        "        limits = current_patch_coords[1]\n",
        "\n",
        "        I1 = self.imgs_1[loc][:, limits[0]:limits[1], limits[2]:limits[3]]\n",
        "        I2 = self.imgs_2[loc][:, limits[0]:limits[1], limits[2]:limits[3]]\n",
        "        label = self.change_maps[loc][limits[0]:limits[1], limits[2]:limits[3]]\n",
        "      \n",
        "\n",
        "        I1 = torch.from_numpy(I1)\n",
        "        I2 = torch.from_numpy(I2)\n",
        "        label = torch.from_numpy(label).float()\n",
        "\n",
        "        sample = {'I1': I1, 'I2': I2, 'label': label}\n",
        "        \n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "        \n",
        "        return sample\n",
        "    \n",
        "    def get_img(self, loc):\n",
        "       return self.imgs_1[loc], self.imgs_2[loc], self.change_maps[loc]\n",
        "\n",
        "\n",
        "    def load_data(self):\n",
        "      #selezione del sottoinsieme richiesto\n",
        "      \n",
        "        if self.train:\n",
        "          self.req_set=train_set\n",
        "        else:\n",
        "          self.req_set=test_set\n",
        "        all_data = []  # Lista per memorizzare tutti i dati da tutti i file\n",
        "        all_imgs = []\n",
        "\n",
        "        #per le patches: dal paper\n",
        "        self.imgs_1 = {}\n",
        "        self.imgs_2 = {}\n",
        "        self.change_maps = {}\n",
        "        self.n_patches_per_image = {}\n",
        "        self.n_patches = 0\n",
        "        self.patch_coords = []\n",
        "        #per i pesi change/no-change  \n",
        "        n_pix = 0\n",
        "        true_pix = 0\n",
        "\n",
        "        for loc in self.req_set:\n",
        "            print('loading:', loc)\n",
        "            img1_list = []\n",
        "            img2_list = []\n",
        "\n",
        "            for channel in channels:\n",
        "                #prendo le immagini di ogni canale e le metto in una lista\n",
        "                ch = Image.open('./drive/MyDrive/OSCD_dataset/OSCD_dataset_images/' + loc + '/imgs_1_rect/' + channel + '.tif')\n",
        "                img1_list.append(np.array(ch))\n",
        "                ch = Image.open('./drive/MyDrive/OSCD_dataset/OSCD_dataset_images/' + loc + '/imgs_2_rect/' + channel + '.tif')\n",
        "                img2_list.append(np.array(ch))    \n",
        "            if self.train:\n",
        "                #carico l'immagine della ground truth\n",
        "                gt = Image.open('./drive/MyDrive/OSCD_dataset/OSCD_dataset_train_labels/' + loc + '/cm/' + loc + '-cm.tif')\n",
        "            else:\n",
        "                gt = Image.open('./drive/MyDrive/OSCD_dataset/OSCD_dataset_test_labels/' + loc + '/cm/' + loc + '-cm.tif')\n",
        "            #la ground truth ha pixel 1 (no change) e 2 (change)\n",
        "            #gt = np.array(gt).reshape(gt.size[0],gt.size[1]) \n",
        "            gt=np.array(gt)-1\n",
        "            '''\n",
        "            print(gt.shape)\n",
        "            plt.imshow(gt)\n",
        "            plt.show()\n",
        "            '''\n",
        "            #reshape dell'immagine alle dimensioni HxWxC\n",
        "            img1=np.array(img1_list).transpose((1,2,0))\n",
        "            img2=np.array(img2_list).transpose((1,2,0))\n",
        "            #print(img1.shape)\n",
        "            if self.normalize:\n",
        "                           \n",
        "              img1=(img1-img1.mean(axis=(0,1)))/img1.std(axis=(0,1))\n",
        "              img2=(img2-img2.mean(axis=(0,1)))/img2.std(axis=(0,1))\n",
        "\n",
        "\n",
        "            #immagine diventa CxHxW come il tensore che la conterrÃ \n",
        "            img1=img1.transpose(2,0,1)\n",
        "            img2=img2.transpose(2,0,1)\n",
        "    \n",
        "            # load and store each image\n",
        "            \n",
        "            self.imgs_1[loc] = img1\n",
        "            self.imgs_2[loc] = img2\n",
        "            self.change_maps[loc] = gt\n",
        "            \n",
        "            s = gt.shape\n",
        "            n_pix += np.prod(s)\n",
        "            true_pix += gt.sum()\n",
        "            \n",
        "            # calculate the number of patches\n",
        "            s = img1.shape\n",
        "            #print(img1.shape)\n",
        "            n1 = ceil((s[1] - self.patch_side + 1) / self.stride)\n",
        "            n2 = ceil((s[2] - self.patch_side + 1) / self.stride)\n",
        "            n_patches_i = n1 * n2\n",
        "            #print(n_patches_i)\n",
        "            self.n_patches_per_image[loc] = n_patches_i\n",
        "            self.n_patches += n_patches_i\n",
        "            \n",
        "            #print(gt.shape)\n",
        "            #print(img1.shape)\n",
        "\n",
        "            # generate path coordinates\n",
        "            for i in range(n1):\n",
        "                for j in range(n2):\n",
        "                    # coordinates in (x1, x2, y1, y2)\n",
        "                    current_patch_coords = (loc, \n",
        "                                    [self.stride*i, self.stride*i + self.patch_side, self.stride*j, self.stride*j + self.patch_side])\n",
        "                    self.patch_coords.append(current_patch_coords)\n",
        "\n",
        "        #self.weights = [ self.CIBW * 2 * true_pix / n_pix, 2 * (n_pix - true_pix) / n_pix]\n",
        "        #RIDEFINIZIONE PESI\n",
        "        self.weights = np.array([ 1 , (n_pix - true_pix) / true_pix])\n",
        "        self.weights = 2 * self.weights/self.weights.sum()\n",
        "        return \n",
        "\n",
        "\n",
        "patch_side=96\n",
        "\n",
        "train_set_imgs=OSCD_dataset(train=True,transform=transform,stride=(int)(patch_side/2) - 1)\n",
        "test_set_imgs=OSCD_dataset(train=False)\n",
        "\n",
        "train_loader = DataLoader(train_set_imgs, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_set_imgs, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YK1XBy-eUcrS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "upD8FpnNZ9C3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWRlL2uwXCBG",
        "outputId": "b4b67618-7936-49bf-cdbb-8c61bf1766fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEFINITIONS OK\n"
          ]
        }
      ],
      "source": [
        "IS_PROTOTYPE = False\n",
        "\n",
        "\n",
        "N_EPOCHS = 10\n",
        "\n",
        "LOAD_TRAINED = False\n",
        "\n",
        "print('DEFINITIONS OK')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KBycYAGWtUf",
        "outputId": "aa415692-950b-4a6b-bbc0-dfaa54a14c4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMPORTS OK\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "from torch.autograd import Variable\n",
        "\n",
        "'''\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as tr\n",
        "'''\n",
        "'''\n",
        "# Models\n",
        "from unet import Unet\n",
        "from siamunet_conc import SiamUnet_conc\n",
        "from siamunet_diff import SiamUnet_diff\n",
        "from fresunet import FresUNet\n",
        "'''\n",
        "'''\n",
        "# Other\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "from skimage import io\n",
        "from scipy.ndimage import zoom\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from tqdm import tqdm as tqdm\n",
        "from pandas import read_csv\n",
        "from math import floor, ceil, sqrt, exp\n",
        "import time\n",
        "from itertools import chain\n",
        "import warnings\n",
        "from pprint import pprint\n",
        "'''\n",
        "import time\n",
        "from IPython import display\n",
        "\n",
        "\n",
        "print('IMPORTS OK')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YBaDc0MMVg5p"
      },
      "outputs": [],
      "source": [
        "# Rodrigo Caye Daudt\n",
        "# https://rcdaudt.github.io/\n",
        "# Daudt, R. C., Le Saux, B., & Boulch, A. \"Fully convolutional siamese networks for change detection\". In 2018 25th IEEE International Conference on Image Processing (ICIP) (pp. 4063-4067). IEEE.\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.modules.padding import ReplicationPad2d\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    \"\"\"EF segmentation network.\"\"\"\n",
        "\n",
        "    def __init__(self, input_nbr, label_nbr):\n",
        "        super(Unet, self).__init__()\n",
        "\n",
        "        self.input_nbr = input_nbr\n",
        "\n",
        "        self.conv11 = nn.Conv2d(input_nbr, 16, kernel_size=3, padding=1)\n",
        "        self.bn11 = nn.BatchNorm2d(16)\n",
        "        self.do11 = nn.Dropout2d(p=0.2)\n",
        "        self.conv12 = nn.Conv2d(16, 16, kernel_size=3, padding=1)\n",
        "        self.bn12 = nn.BatchNorm2d(16)\n",
        "        self.do12 = nn.Dropout2d(p=0.2)\n",
        "\n",
        "        self.conv21 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "        self.bn21 = nn.BatchNorm2d(32)\n",
        "        self.do21 = nn.Dropout2d(p=0.2)\n",
        "        self.conv22 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
        "        self.bn22 = nn.BatchNorm2d(32)\n",
        "        self.do22 = nn.Dropout2d(p=0.2)\n",
        "\n",
        "        self.conv31 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn31 = nn.BatchNorm2d(64)\n",
        "        self.do31 = nn.Dropout2d(p=0.2)\n",
        "        self.conv32 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.bn32 = nn.BatchNorm2d(64)\n",
        "        self.do32 = nn.Dropout2d(p=0.2)\n",
        "        self.conv33 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.bn33 = nn.BatchNorm2d(64)\n",
        "        self.do33 = nn.Dropout2d(p=0.2)\n",
        "\n",
        "        self.conv41 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn41 = nn.BatchNorm2d(128)\n",
        "        self.do41 = nn.Dropout2d(p=0.2)\n",
        "        self.conv42 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        self.bn42 = nn.BatchNorm2d(128)\n",
        "        self.do42 = nn.Dropout2d(p=0.2)\n",
        "        self.conv43 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        self.bn43 = nn.BatchNorm2d(128)\n",
        "        self.do43 = nn.Dropout2d(p=0.2)\n",
        "\n",
        "\n",
        "        self.upconv4 = nn.ConvTranspose2d(128, 128, kernel_size=3, padding=1, stride=2, output_padding=1)\n",
        "\n",
        "        self.conv43d = nn.ConvTranspose2d(256, 128, kernel_size=3, padding=1)\n",
        "        self.bn43d = nn.BatchNorm2d(128)\n",
        "        self.do43d = nn.Dropout2d(p=0.2)\n",
        "        self.conv42d = nn.ConvTranspose2d(128, 128, kernel_size=3, padding=1)\n",
        "        self.bn42d = nn.BatchNorm2d(128)\n",
        "        self.do42d = nn.Dropout2d(p=0.2)\n",
        "        self.conv41d = nn.ConvTranspose2d(128, 64, kernel_size=3, padding=1)\n",
        "        self.bn41d = nn.BatchNorm2d(64)\n",
        "        self.do41d = nn.Dropout2d(p=0.2)\n",
        "\n",
        "        self.upconv3 = nn.ConvTranspose2d(64, 64, kernel_size=3, padding=1, stride=2, output_padding=1)\n",
        "\n",
        "        self.conv33d = nn.ConvTranspose2d(128, 64, kernel_size=3, padding=1)\n",
        "        self.bn33d = nn.BatchNorm2d(64)\n",
        "        self.do33d = nn.Dropout2d(p=0.2)\n",
        "        self.conv32d = nn.ConvTranspose2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.bn32d = nn.BatchNorm2d(64)\n",
        "        self.do32d = nn.Dropout2d(p=0.2)\n",
        "        self.conv31d = nn.ConvTranspose2d(64, 32, kernel_size=3, padding=1)\n",
        "        self.bn31d = nn.BatchNorm2d(32)\n",
        "        self.do31d = nn.Dropout2d(p=0.2)\n",
        "\n",
        "        self.upconv2 = nn.ConvTranspose2d(32, 32, kernel_size=3, padding=1, stride=2, output_padding=1)\n",
        "\n",
        "        self.conv22d = nn.ConvTranspose2d(64, 32, kernel_size=3, padding=1)\n",
        "        self.bn22d = nn.BatchNorm2d(32)\n",
        "        self.do22d = nn.Dropout2d(p=0.2)\n",
        "        self.conv21d = nn.ConvTranspose2d(32, 16, kernel_size=3, padding=1)\n",
        "        self.bn21d = nn.BatchNorm2d(16)\n",
        "        self.do21d = nn.Dropout2d(p=0.2)\n",
        "\n",
        "        self.upconv1 = nn.ConvTranspose2d(16, 16, kernel_size=3, padding=1, stride=2, output_padding=1)\n",
        "\n",
        "        self.conv12d = nn.ConvTranspose2d(32, 16, kernel_size=3, padding=1)\n",
        "        self.bn12d = nn.BatchNorm2d(16)\n",
        "        self.do12d = nn.Dropout2d(p=0.2)\n",
        "        self.conv11d = nn.ConvTranspose2d(16, label_nbr, kernel_size=3, padding=1)\n",
        "\n",
        "        self.sm = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "\n",
        "        x = torch.cat((x1, x2), 1)\n",
        "        \n",
        "        #x11 = F.relu(self.bn11(self.conv11(x)))\n",
        "        #x12 = F.relu(self.bn12(self.conv12(x11)))\n",
        "        \n",
        "        \"\"\"Forward method.\"\"\"\n",
        "        # Stage 1\n",
        "        x11 = self.do11(F.relu(self.bn11(self.conv11(x))))\n",
        "        x12 = self.do12(F.relu(self.bn12(self.conv12(x11))))\n",
        "        x1p = F.max_pool2d(x12, kernel_size=2, stride=2)\n",
        "\n",
        "        # Stage 2\n",
        "        x21 = self.do21(F.relu(self.bn21(self.conv21(x1p))))\n",
        "        x22 = self.do22(F.relu(self.bn22(self.conv22(x21))))\n",
        "        #x21 = F.relu(self.bn21(self.conv21(x1p)))\n",
        "        #x22 = F.relu(self.bn22(self.conv22(x21)))\n",
        "        x2p = F.max_pool2d(x22, kernel_size=2, stride=2)\n",
        "\n",
        "        # Stage 3\n",
        "        x31 = self.do31(F.relu(self.bn31(self.conv31(x2p))))\n",
        "        x32 = self.do32(F.relu(self.bn32(self.conv32(x31))))\n",
        "        x33 = self.do33(F.relu(self.bn33(self.conv33(x32))))\n",
        "        #x31 = F.relu(self.bn31(self.conv31(x2p)))\n",
        "        #x32 = F.relu(self.bn32(self.conv32(x31)))\n",
        "        #x33 = F.relu(self.bn33(self.conv33(x32)))\n",
        "        x3p = F.max_pool2d(x33, kernel_size=2, stride=2)\n",
        "\n",
        "        # Stage 4\n",
        "        #x41 = F.relu(self.bn41(self.conv41(x3p)))\n",
        "        #x42 = F.relu(self.bn42(self.conv42(x41)))\n",
        "        #x43 = F.relu(self.bn43(self.conv43(x42)))\n",
        "        x41 = self.do41(F.relu(self.bn41(self.conv41(x3p))))\n",
        "        x42 = self.do42(F.relu(self.bn42(self.conv42(x41))))\n",
        "        x43 = self.do43(F.relu(self.bn43(self.conv43(x42))))\n",
        "        x4p = F.max_pool2d(x43, kernel_size=2, stride=2)\n",
        "\n",
        "\n",
        "        # Stage 4d\n",
        "        x4d = self.upconv4(x4p)\n",
        "        pad4 = ReplicationPad2d((0, x43.size(3) - x4d.size(3), 0, x43.size(2) - x4d.size(2)))\n",
        "        x4d = torch.cat((pad4(x4d), x43), 1)\n",
        "        #x43d = F.relu(self.bn43d(self.conv43d(x4d)))\n",
        "        #x42d = F.relu(self.bn42d(self.conv42d(x43d)))\n",
        "        #x41d = F.relu(self.bn41d(self.conv41d(x42d)))\n",
        "        x43d = self.do43d(F.relu(self.bn43d(self.conv43d(x4d))))\n",
        "        x42d = self.do42d(F.relu(self.bn42d(self.conv42d(x43d))))\n",
        "        x41d = self.do41d(F.relu(self.bn41d(self.conv41d(x42d))))\n",
        "\n",
        "        # Stage 3d\n",
        "        x3d = self.upconv3(x41d)\n",
        "        pad3 = ReplicationPad2d((0, x33.size(3) - x3d.size(3), 0, x33.size(2) - x3d.size(2)))\n",
        "        x3d = torch.cat((pad3(x3d), x33), 1)\n",
        "        #x33d = F.relu(self.bn33d(self.conv33d(x3d)))\n",
        "        #x32d = F.relu(self.bn32d(self.conv32d(x33d)))\n",
        "        #x31d = F.relu(self.bn31d(self.conv31d(x32d)))\n",
        "        x33d = self.do33d(F.relu(self.bn33d(self.conv33d(x3d))))\n",
        "        x32d = self.do32d(F.relu(self.bn32d(self.conv32d(x33d))))\n",
        "        x31d = self.do31d(F.relu(self.bn31d(self.conv31d(x32d))))\n",
        "\n",
        "        # Stage 2d\n",
        "        x2d = self.upconv2(x31d)\n",
        "        pad2 = ReplicationPad2d((0, x22.size(3) - x2d.size(3), 0, x22.size(2) - x2d.size(2)))\n",
        "        x2d = torch.cat((pad2(x2d), x22), 1)\n",
        "        #x22d = F.relu(self.bn22d(self.conv22d(x2d)))\n",
        "        #x21d = F.relu(self.bn21d(self.conv21d(x22d)))\n",
        "        x22d = self.do22d(F.relu(self.bn22d(self.conv22d(x2d))))\n",
        "        x21d = self.do21d(F.relu(self.bn21d(self.conv21d(x22d))))\n",
        "\n",
        "        # Stage 1d\n",
        "        x1d = self.upconv1(x21d)\n",
        "        pad1 = ReplicationPad2d((0, x12.size(3) - x1d.size(3), 0, x12.size(2) - x1d.size(2)))\n",
        "        x1d = torch.cat((pad1(x1d), x12), 1)\n",
        "        #x12d = F.relu(self.bn12d(self.conv12d(x1d)))\n",
        "        x12d = self.do12d(F.relu(self.bn12d(self.conv12d(x1d))))\n",
        "        x11d = self.conv11d(x12d)\n",
        "\n",
        "        return self.sm(x11d)\n",
        "\n",
        "net, net_name = Unet(2*13, 2), 'FC-EF'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxHpqfi9U-2C",
        "outputId": "49eb4ec8-576f-4ab2-8fa7-52d6fbf1c1c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of trainable parameters: 1353458\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print('Number of trainable parameters:', count_parameters(net))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xhz2pC5AXbkX",
        "outputId": "6ec034bb-3213-43a1-f082-f534c4e17627"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using PyTorch version: 2.0.1+cu118  Device: cuda\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    \n",
        "print('Using PyTorch version:', torch.__version__, ' Device:', device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xv9LtDbYcXP",
        "outputId": "b2372b2f-8f51-449f-f74f-f896ff676640"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0458, 1.9542], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unet(\n",
              "  (conv11): Conv2d(26, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (do11): Dropout2d(p=0.2, inplace=False)\n",
              "  (conv12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn12): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (do12): Dropout2d(p=0.2, inplace=False)\n",
              "  (conv21): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn21): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (do21): Dropout2d(p=0.2, inplace=False)\n",
              "  (conv22): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn22): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (do22): Dropout2d(p=0.2, inplace=False)\n",
              "  (conv31): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn31): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (do31): Dropout2d(p=0.2, inplace=False)\n",
              "  (conv32): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn32): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (do32): Dropout2d(p=0.2, inplace=False)\n",
              "  (conv33): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn33): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (do33): Dropout2d(p=0.2, inplace=False)\n",
              "  (conv41): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn41): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (do41): Dropout2d(p=0.2, inplace=False)\n",
              "  (conv42): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn42): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (do42): Dropout2d(p=0.2, inplace=False)\n",
              "  (conv43): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn43): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (do43): Dropout2d(p=0.2, inplace=False)\n",
              "  (upconv4): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
              "  (conv43d): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn43d): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (do43d): Dropout2d(p=0.2, inplace=False)\n",
              "  (conv42d): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn42d): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (do42d): Dropout2d(p=0.2, inplace=False)\n",
              "  (conv41d): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn41d): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (do41d): Dropout2d(p=0.2, inplace=False)\n",
              "  (upconv3): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
              "  (conv33d): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn33d): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (do33d): Dropout2d(p=0.2, inplace=False)\n",
              "  (conv32d): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn32d): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (do32d): Dropout2d(p=0.2, inplace=False)\n",
              "  (conv31d): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn31d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (do31d): Dropout2d(p=0.2, inplace=False)\n",
              "  (upconv2): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
              "  (conv22d): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn22d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (do22d): Dropout2d(p=0.2, inplace=False)\n",
              "  (conv21d): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn21d): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (do21d): Dropout2d(p=0.2, inplace=False)\n",
              "  (upconv1): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
              "  (conv12d): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn12d): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (do12d): Dropout2d(p=0.2, inplace=False)\n",
              "  (conv11d): ConvTranspose2d(16, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (sm): LogSoftmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "weights = torch.FloatTensor(train_set_imgs.weights).to(device)\n",
        "print(weights)\n",
        "#criterion = nn.NLLLoss(weight=weights).to(device) # to be used with logsoftmax output\n",
        "#criterion = nn.CrossEntrpyLoss(weight=weights).to(device) # to be used with logsoftmax output\n",
        "\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "  def __init__(self,gamma=3,alpha=0.1,reduction='mean'):\n",
        "    super(FocalLoss, self).__init__()\n",
        "    self.gamma=gamma\n",
        "    self.alpha=alpha\n",
        "    self.reduction=reduction\n",
        "  def forward(self,output,label):\n",
        "    pt=torch.exp(output)\n",
        "    #Output NxCxHxW -> NxCxH*W\n",
        "    output=output.view(output.shape[0],output.shape[1],-1)\n",
        "    pt=pt.view(pt.shape[0],pt.shape[1],-1)\n",
        "    #Label NxHxW -> NxH*W\n",
        "    label=label.view(label.shape[0],-1)\n",
        "\n",
        "    #Output NxCxH*W -> NxH*WxC -> N*H*WxC\n",
        "    #output=output.transpose(1,2)\n",
        "    #pt=pt.transpose(1,2)\n",
        "\n",
        "    #output=output.contiguous().view(-1,output.shape[2])\n",
        "    #pt=pt.contiguous().view(-1,pt.shape[2])\n",
        "\n",
        "    output=output.transpose(0,1)\n",
        "    pt=pt.transpose(0,1)\n",
        "    #output=output.squeeze(0)\n",
        "    #pt=pt.squeeze(0)\n",
        "    #Label NxH*W -> N*H*W\n",
        "    #label=label.view(-1)\n",
        "\n",
        "    no_change_loss=-((1-label)*self.alpha*((1-pt[0])**self.gamma)*output[0]).sum(axis=1)\n",
        "    change_loss=-((label)*(1-self.alpha)*((1-pt[1])**self.gamma)*output[1]).sum(axis=1)\n",
        "    #print(pt[0]+pt[1])\n",
        "    #print('change',change_loss.mean())\n",
        "    #print('no_change',no_change_loss.mean())\n",
        "    focal_loss=change_loss+no_change_loss\n",
        "    #print(focal_loss.shape)\n",
        "    if self.reduction == 'mean':\n",
        "        focal_loss = torch.mean(focal_loss)\n",
        "    elif self.reduction == 'sum':\n",
        "        focal_loss = torch.sum(focal_loss)\n",
        "    return focal_loss\n",
        "\n",
        "criterion = FocalLoss().to(device)\n",
        "    \n",
        "\n",
        "net.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VjGlKnveBRVl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AuPlQ4_8LXq3",
        "outputId": "081f5c40-685d-4d3b-fdfd-abf7a73d706e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 of 10\n",
            "aguasclaras\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=525x471 at 0x7F441E1C1300>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bercy\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=360x395 at 0x7F441E1C1D80>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bordeaux\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=461x517 at 0x7F441E1C33A0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nantes\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=582x522 at 0x7F441E1C1300>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "paris\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=390x408 at 0x7F441E1C0A60>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAGYCAIAAADJPtJZAAALnklEQVR4nO3d63abOBQGUDSr7//Kmh9pHdtgjI2QjqS916yOkyYuiMNnSdyWBQCAtdR6AZhafvF9dTktm542XoXRjdKck+1OA2/z6MeZ6rz/J1R5R2wsqjoYRjffFWheliXnZVmWlM68D/XZUtTzaR4tXxXobx49vFFS612wmajni0havk6l5SGYgifSumVCL+6Vpl1xavsuj5YzkXTiHarZb5bIS36RP60XAMobZk/OA63LQbOtLy1VG7j1QoOs/dd6AYDPfD0E7oJIop5PP97T0D2COMkSZ0kWc0lUloLtACO5NezxHA+4LUQSEQ3cOTpvs3Hy4+u09VddtKqBG1UdubStiz3nvO9W89Pfyi9en1+Si+glEUKovSKsg610+7F1Bj11oAI2u0iimYD7Q2UHZ9Y+aqi3Pxz8TPFQCwOUdHz2Ok4QmEuCYcUJmuNEEhCISILZhepMiSQYWai4OaK7BQa+0cVJScCkAl5KAhBAfghIc0lAO3nJS85L1m0DYsiGkQAAAD1xUgIMa2eKJuyeH3bBgG33QbOzAx+cMo4WAdGWB9izGTTpwM/sCJUCbuEG3RvpGLpTJaEbF0VPqEQTSUAgIgn6EKovc51QE1vwrZ+rpFJaQtb0U5q8WsKdB65VyKMg7RZkMeCE+6s2U4pW01ccI7tU2wZ0xA0u9CprQmXQk4N9uouYS4KrRM6d4yqvhUhiBGlJy7KkSKO2MfLoR811ibMF4YQcrpZHiqSb+zY+eF3LmX8CKGbISHqlYI4YuEF5U+VRWSIJCEQkAYGIJOCUshPSIgn4XvEDZCIJypvkSPYVqzlJ00EbAx96uyg7RBJca7xUujQ1DNyAD1zdixFJcK2RRiIV1mWk5oLQ9m+cFHx8Vy0pRBJUtXPryKcfiKNmTIgkiK5hSNUPCJEEfZjkpkUiCXoy/HMBRBL052lCqmBONU+E5gsAlHE+mCLEQYRlAIr5LpgEAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAkXjuLtO5PaJa9QdkozCF/OL7doBobBEGl/OrOPorJXtBIH9aLwCUlu9fvsmjvz8vlML4r/UCQFEHIqjYb3EBkcRY7vo7h7pIq9+iLZHEcD7Kl5Ry0kkKRCQxnH8Bk46E07vJbyoTSQwn3b98l0opLfv9KpFVlzE04/tNlXWfaP8UAGdVVqeXxPh+8+Qpf5ySFI8twlx++j1H614vCYjFXBIAAAAAAAAAAAAAAAAAAAAA1JTd9INt7kxFLZsZpAB55Ea3VKFPxDE+pKhlnUqqL7Ymt/lVFMCG+0+QmjFh4AYEIpKAPUZSQAiOSQAAALBm6ooveTY1V3DEjW+Y+OQiIgkIRCRxilEbAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADlpdYLQDH53wsblX7913oBKCO/eA19EUkjeMogvST6JZJGIIMYhkgazWfxlA3ziMXna3u51Wa4DyOFQAwqsbHrDpO96v2k9V+rAsIwcGvpujHTp+9sAEcQf1ovAFVt9IfSbxjdDyH1omhCL6mZ+r2StP4ibf+AHhOtiKQ2rj6TKK2+3OwfHVkGXSRqUm8NrPsgNgP80EuqJK9ebP4tTO7Fx3Pe+0s+dSRxNDYsezuCVCrno06QJmdmLwduecl5yTkbUhRwMmVsA+axt7Pc8igln9wFGL7BW292gZxz+vkZ+0ohO8F0vo2d30jvjtWteaUeuGsSAzh2QYnqBgBmo//DG54yQE3KrLFX03SfTgwdPFHg1fs85c7+uykarqO6mil4/uSZt/ripKf7GwYoIMpyv6TpFDzxUh5RnMtumzm+P4fa80MtDOMRSS1t38YosL6Wlh4ZuHGIMKIOlRbCycvfLr0uV4lQk4FbCGn1Yi3f/Qej8hEY1NvcOXICURFKhJrUW2hvT1k8mFwfve3x94HiVFoHNhPk7QOOdk5o/LpvpVy4mhrrxttrzV6dS/3qF78LJhXDpZwE0I23WSAsGIBIaqzOdfabb15tghyO88naUrT7QH43WQ4FOS+pmYDdk/0LXOQRFRi48ew+ety/jcpEEnskEZWJJHqlBzckW7OlaNPbHdk/fZR+2YiNjfRRX21d3Bp8YDZfUDpQm44fptRinQo0l+SRujfrHc+N91/K/1oraaERhDgv6f4eQAHP1iGIjdrIefs13WofSb919K+kJq+syVf/AzJoRI0j6TmPFBkHKZVBte8l/fUzEZDSMv2kyc4lsvzVKI/cZbiCxpH0sKfJo3/S42tt0tzTdKdguk6Iah/p3Byu8xAE647S4xG3grW0E0AqtjhNSjeeo+HF4f/iNe2eLTVpTHrSKh2kUjVhprfhgP09/0wueEZeEMKdLq2z4+tSPvJWJx9HzHGakb6dvw7peLqZ564g0DVulHK/50yyq9S5BvDVM6kmaeQ6zCWNJu9+OZgIayePyhJJ9KpUHsmUUEQSIzgZK+nFa+ozlzS4GXawIus4Q0NBG5OfYjPtio/BZwPjcHfgAdhqjKPg+ZPku0sIazaj6W0GYbxWUH68g3DNtr02kmae0aAyHaIx6CUxjrT7JV+r2ZLXngSgJqhMyfVOLwl4dj+jXXd2GwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABiax6HwjfuHGKshCvIcNyAQkcTH8vsfgS+JJE4xaqMskcT35BEQgrEbF/E5V5LjUHCSgVtJYggAAAAAAGA+jhGFtj79xwZjbE4CAAIRSUAgIim0tPsljEckAYHM/rn7NH8ctjly4GWDgqau87wsS34MpZSWyRsFmpp34LaRR5vfASqaN5KAgOaOpLQaoq2/A1Q09R64OUibukWA5rLbtkIY+gQXct9b+NTcc0lAMCIJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACK8yyfEDxeCX6o//bysiz5LpSSp4AzLw9Nauw5j9ZfwkxEUmsCCO6IpKbyklZj5/V3YB4iqT0ZBDciqalVFoknJieSWktLXvLTd2BaIimA20H/pJMEBOCoGwAAr2UdxumZuqCBI7mjNOdku3PUU458VzqfdoIU6GxscTYcD463BVRwIKZYZ2Ar8+u7+HhVQ1fMCqnX4dnEUyuVGvdlVGF+WtUOzMadV/EhVf2DZcp3PM7entEwx9rHWAvu+ZiZyKg7sCIeyZ/WC8DlRk0ihiSShiWJ6JFIGo0komumt4fSKo/M5lCKSBqH/hEDEEl0TxaPRCQNwm7JGEQSBQhEShFJQCAiaQQ6KQxDJNE9pyCMRCR1TxeJkfiAOaXIvV8LLsCEVPBg9JJOsT9AWSLprLR6QTXafDwdb9P7MUvHq3GCUduc231sXd4JYL0r/nxHgULvRhm45el6DNOt8IpPoCH1t1mfd8X7MEqpv/X51iSRNM8G5UeXA7dfj3nUbjkoz+acU7cDt5w382iSvsOm1G43Fh9dCrm39BlJTzNHj/2jkO18ucFCYbDViSjf/RlJhwO3d4O1Sao5LUueZmUpLD++jlRGkZbluLzkJc+cRzvifex9w3a8Vr79/++rOEeGOuwlLcuSlqRot8gjDklxa8XWH0rUMvuAiqznVi6RGr3PXhJwXqQkuunziBswKJEEBBKy61ZX89uwlWU6ia5NvPXzzx8bZzn13ii9p1Lv7c8Zsw7c8pKXnJ923lFuJ2CXpl+TRtJzGP1IaRllf658vVvBf2uM9udrM54EMEhf6IDb7j3PKtO7GT+T/u6fW9fuDt8c62xK737giCInAw/f+BwxYy9pY/+ZI4+WA+tY80qDGRqcT006l7Qsd3cRSKnhnYYCqtAUGpxXFAbbPuor3ZfR/i8qOPapEN44kk3KiFLUEu/tpJICoiwVxSGDXXYDAABd0QHnGyHvR8gIJj4viRJcqgKEkOURAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMBL/wO917u3JcJ3xwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rennes\n"
          ]
        }
      ],
      "source": [
        "def train(n_epochs = 10, save = True):\n",
        "    t = np.linspace(1, n_epochs, n_epochs)\n",
        "    \n",
        "    epoch_train_loss = 0 * t\n",
        "    epoch_train_accuracy = 0 * t\n",
        "    epoch_train_change_accuracy = 0 * t\n",
        "    epoch_train_nochange_accuracy = 0 * t\n",
        "    epoch_train_precision = 0 * t\n",
        "    epoch_train_recall = 0 * t\n",
        "    epoch_train_Fmeasure = 0 * t\n",
        "    epoch_test_loss = 0 * t\n",
        "    epoch_test_accuracy = 0 * t\n",
        "    epoch_test_change_accuracy = 0 * t\n",
        "    epoch_test_nochange_accuracy = 0 * t\n",
        "    epoch_test_precision = 0 * t\n",
        "    epoch_test_recall = 0 * t\n",
        "    epoch_test_Fmeasure = 0 * t\n",
        "    \n",
        "#     mean_acc = 0\n",
        "#     best_mean_acc = 0\n",
        "    fm = 0\n",
        "    best_fm = 0\n",
        "    \n",
        "    lss = 1000\n",
        "    best_lss = 1000\n",
        "    \n",
        "    plt.figure(num=1)\n",
        "    plt.figure(num=2)\n",
        "    plt.figure(num=3)\n",
        "    \n",
        "    \n",
        "    optimizer = torch.optim.Adam(net.parameters(), weight_decay=1e-4)\n",
        "#     optimizer = torch.optim.Adam(net.parameters(), lr=0.0005)\n",
        "        \n",
        "    \n",
        "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.95)\n",
        "    \n",
        "    \n",
        "    for epoch_index in range(N_EPOCHS):\n",
        "        net.train()\n",
        "        print('Epoch: ' + str(epoch_index + 1) + ' of ' + str(N_EPOCHS))\n",
        "\n",
        "        tot_count = 0\n",
        "        tot_loss = 0\n",
        "        tot_accurate = 0\n",
        "        class_correct = list(0. for i in range(2))\n",
        "        class_total = list(0. for i in range(2))\n",
        "#         for batch_index, batch in enumerate(tqdm(data_loader)):\n",
        "        for batch in train_loader:\n",
        "            I1 = Variable(batch['I1'].float()).to(device)\n",
        "            I2 = Variable(batch['I2'].float()).to(device)\n",
        "            label = Variable(batch['label']).to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = net(I1, I2)\n",
        "            loss = criterion(output, label.long())\n",
        "            #print(loss.item(),loss.mean(),loss.sum())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "        scheduler.step()\n",
        "\n",
        "\n",
        "        epoch_train_loss[epoch_index], epoch_train_accuracy[epoch_index], cl_acc, pr_rec = test(train_set_imgs)\n",
        "        epoch_train_nochange_accuracy[epoch_index] = cl_acc[0]\n",
        "        epoch_train_change_accuracy[epoch_index] = cl_acc[1]\n",
        "        epoch_train_precision[epoch_index] = pr_rec[0]\n",
        "        epoch_train_recall[epoch_index] = pr_rec[1]\n",
        "        epoch_train_Fmeasure[epoch_index] = pr_rec[2]\n",
        "        \n",
        "#         epoch_test_loss[epoch_index], epoch_test_accuracy[epoch_index], cl_acc, pr_rec = test(test_dataset)\n",
        "        epoch_test_loss[epoch_index], epoch_test_accuracy[epoch_index], cl_acc, pr_rec = test(test_set_imgs)\n",
        "        epoch_test_nochange_accuracy[epoch_index] = cl_acc[0]\n",
        "        epoch_test_change_accuracy[epoch_index] = cl_acc[1]\n",
        "        epoch_test_precision[epoch_index] = pr_rec[0]\n",
        "        epoch_test_recall[epoch_index] = pr_rec[1]\n",
        "        epoch_test_Fmeasure[epoch_index] = pr_rec[2]\n",
        "\n",
        "        plt.figure(num=1)\n",
        "        plt.clf()\n",
        "        l1_1, = plt.plot(t[:epoch_index + 1], epoch_train_loss[:epoch_index + 1], label='Train loss')\n",
        "        l1_2, = plt.plot(t[:epoch_index + 1], epoch_test_loss[:epoch_index + 1], label='Test loss')\n",
        "        plt.legend(handles=[l1_1, l1_2])\n",
        "        plt.grid()\n",
        "#         plt.gcf().gca().set_ylim(bottom = 0)\n",
        "        plt.gcf().gca().set_xlim(left = 0)\n",
        "        plt.title('Loss')\n",
        "        display.clear_output(wait=True)\n",
        "        display.display(plt.gcf())\n",
        "\n",
        "        plt.figure(num=2)\n",
        "        plt.clf()\n",
        "        l2_1, = plt.plot(t[:epoch_index + 1], epoch_train_accuracy[:epoch_index + 1], label='Train accuracy')\n",
        "        l2_2, = plt.plot(t[:epoch_index + 1], epoch_test_accuracy[:epoch_index + 1], label='Test accuracy')\n",
        "        plt.legend(handles=[l2_1, l2_2])\n",
        "        plt.grid()\n",
        "        plt.gcf().gca().set_ylim(0, 100)\n",
        "#         plt.gcf().gca().set_ylim(bottom = 0)\n",
        "#         plt.gcf().gca().set_xlim(left = 0)\n",
        "        plt.title('Accuracy')\n",
        "        display.display(plt.gcf())\n",
        "\n",
        "        plt.figure(num=3)\n",
        "        plt.clf()\n",
        "        l3_1, = plt.plot(t[:epoch_index + 1], epoch_train_nochange_accuracy[:epoch_index + 1], label='Train accuracy: no change')\n",
        "        l3_2, = plt.plot(t[:epoch_index + 1], epoch_train_change_accuracy[:epoch_index + 1], label='Train accuracy: change')\n",
        "        l3_3, = plt.plot(t[:epoch_index + 1], epoch_test_nochange_accuracy[:epoch_index + 1], label='Test accuracy: no change')\n",
        "        l3_4, = plt.plot(t[:epoch_index + 1], epoch_test_change_accuracy[:epoch_index + 1], label='Test accuracy: change')\n",
        "        plt.legend(handles=[l3_1, l3_2, l3_3, l3_4])\n",
        "        plt.grid()\n",
        "        plt.gcf().gca().set_ylim(0, 100)\n",
        "#         plt.gcf().gca().set_ylim(bottom = 0)\n",
        "#         plt.gcf().gca().set_xlim(left = 0)\n",
        "        plt.title('Accuracy per class')\n",
        "        display.display(plt.gcf())\n",
        "\n",
        "        plt.figure(num=4)\n",
        "        plt.clf()\n",
        "        l4_1, = plt.plot(t[:epoch_index + 1], epoch_train_precision[:epoch_index + 1], label='Train precision')\n",
        "        l4_2, = plt.plot(t[:epoch_index + 1], epoch_train_recall[:epoch_index + 1], label='Train recall')\n",
        "        l4_3, = plt.plot(t[:epoch_index + 1], epoch_train_Fmeasure[:epoch_index + 1], label='Train Dice/F1')\n",
        "        l4_4, = plt.plot(t[:epoch_index + 1], epoch_test_precision[:epoch_index + 1], label='Test precision')\n",
        "        l4_5, = plt.plot(t[:epoch_index + 1], epoch_test_recall[:epoch_index + 1], label='Test recall')\n",
        "        l4_6, = plt.plot(t[:epoch_index + 1], epoch_test_Fmeasure[:epoch_index + 1], label='Test Dice/F1')\n",
        "        plt.legend(handles=[l4_1, l4_2, l4_3, l4_4, l4_5, l4_6])\n",
        "        plt.grid()\n",
        "        plt.gcf().gca().set_ylim(0, 1)\n",
        "#         plt.gcf().gca().set_ylim(bottom = 0)\n",
        "#         plt.gcf().gca().set_xlim(left = 0)\n",
        "        plt.title('Precision, Recall and F-measure')\n",
        "        display.display(plt.gcf())\n",
        "        \n",
        "        \n",
        "#         mean_acc = (epoch_test_nochange_accuracy[epoch_index] + epoch_test_change_accuracy[epoch_index])/2\n",
        "#         if mean_acc > best_mean_acc:\n",
        "#             best_mean_acc = mean_acc\n",
        "#             save_str = 'net-best_epoch-' + str(epoch_index + 1) + '_acc-' + str(mean_acc) + '.pth.tar'\n",
        "#             torch.save(net.state_dict(), save_str)\n",
        "        \n",
        "        \n",
        "#         fm = pr_rec[2]\n",
        "        fm = epoch_train_Fmeasure[epoch_index]\n",
        "        if fm > best_fm:\n",
        "            best_fm = fm\n",
        "            save_str = 'net-best_epoch-' + str(epoch_index + 1) + '_fm-' + str(fm) + '.pth.tar'\n",
        "            torch.save(net.state_dict(), save_str)\n",
        "        \n",
        "        lss = epoch_train_loss[epoch_index]\n",
        "        if lss < best_lss:\n",
        "            best_lss = lss\n",
        "            save_str = 'net-best_epoch-' + str(epoch_index + 1) + '_loss-' + str(lss) + '.pth.tar'\n",
        "            torch.save(net.state_dict(), save_str)\n",
        "            \n",
        "            \n",
        "#         print('Epoch loss: ' + str(tot_loss/tot_count))\n",
        "        if save:\n",
        "            im_format = 'png'\n",
        "    #         im_format = 'eps'\n",
        "\n",
        "            plt.figure(num=1)\n",
        "            plt.savefig(net_name + '-01-loss.' + im_format)\n",
        "\n",
        "            plt.figure(num=2)\n",
        "            plt.savefig(net_name + '-02-accuracy.' + im_format)\n",
        "\n",
        "            plt.figure(num=3)\n",
        "            plt.savefig(net_name + '-03-accuracy-per-class.' + im_format)\n",
        "\n",
        "            plt.figure(num=4)\n",
        "            plt.savefig(net_name + '-04-prec-rec-fmeas.' + im_format)\n",
        "        \n",
        "    out = {'train_loss': epoch_train_loss[-1],\n",
        "           'train_accuracy': epoch_train_accuracy[-1],\n",
        "           'train_nochange_accuracy': epoch_train_nochange_accuracy[-1],\n",
        "           'train_change_accuracy': epoch_train_change_accuracy[-1],\n",
        "           'test_loss': epoch_test_loss[-1],\n",
        "           'test_accuracy': epoch_test_accuracy[-1],\n",
        "           'test_nochange_accuracy': epoch_test_nochange_accuracy[-1],\n",
        "           'test_change_accuracy': epoch_test_change_accuracy[-1]}\n",
        "    \n",
        "    print('pr_c, rec_c, f_meas, pr_nc, rec_nc')\n",
        "    print(pr_rec)\n",
        "    \n",
        "    return out\n",
        "\n",
        "L = 1024\n",
        "N = 2\n",
        "\n",
        "def test(dset):\n",
        "\n",
        "    net.eval()\n",
        "    tot_loss = 0\n",
        "    tot_count = 0\n",
        "    tot_accurate = 0\n",
        "    \n",
        "    n = 2\n",
        "    class_correct = list(0. for i in range(n))\n",
        "    class_total = list(0. for i in range(n))\n",
        "    class_accuracy = list(0. for i in range(n))\n",
        "    \n",
        "    tp = 0\n",
        "    tn = 0\n",
        "    fp = 0\n",
        "    fn = 0\n",
        "    \n",
        "    if dset.train:\n",
        "      req_set=train_set\n",
        "    else:\n",
        "      req_set=test_set\n",
        "\n",
        "    for img_index in req_set:\n",
        "        I1_full, I2_full, cm_full = dset.get_img(img_index)\n",
        "        \n",
        "        s = cm_full.shape\n",
        "\n",
        "        # Crea un'immagine RGB bianca delle stesse dimensioni dell'immagine di input\n",
        "        result_image = np.zeros((s[0], s[1], 3), dtype=np.uint8) \n",
        "\n",
        "       \n",
        "        print(img_index)\n",
        "        \n",
        "        steps0 = np.arange(0,s[0],ceil(s[0]/N))\n",
        "        steps1 = np.arange(0,s[1],ceil(s[1]/N))\n",
        "        for ii in range(N):\n",
        "            for jj in range(N):\n",
        "                xmin = steps0[ii]\n",
        "                if ii == N-1:\n",
        "                    xmax = s[0]\n",
        "                else:\n",
        "                    xmax = steps0[ii+1]\n",
        "                ymin = steps1[jj]\n",
        "                if jj == N-1:\n",
        "                    ymax = s[1]\n",
        "                else:\n",
        "                    ymax = steps1[jj+1]\n",
        "                I1 = I1_full[:, xmin:xmax, ymin:ymax]\n",
        "                I2 = I2_full[:, xmin:xmax, ymin:ymax]\n",
        "                cm = cm_full[xmin:xmax, ymin:ymax]\n",
        "\n",
        "                #print(cm_full.shape)\n",
        "\n",
        "                I1=torch.from_numpy(I1)\n",
        "                I2=torch.from_numpy(I2)\n",
        "\n",
        "                I1 = Variable(torch.unsqueeze(I1, 0).float()).to(device)\n",
        "                I2 = Variable(torch.unsqueeze(I2, 0).float()).to(device)\n",
        "                cm = Variable(torch.unsqueeze(torch.from_numpy(1.0*cm),0).float()).to(device)\n",
        "\n",
        "\n",
        "                output = net(I1, I2)\n",
        "                loss = criterion(output, cm.long())\n",
        "        #         print(loss)\n",
        "                tot_loss += loss.data * np.prod(cm.size())\n",
        "                tot_count += np.prod(cm.size())\n",
        "\n",
        "                _, predicted = torch.max(output.data, 1)\n",
        "\n",
        "                c = (predicted.int() == cm.data.int())\n",
        "                for i in range(c.size(1)):\n",
        "                    for j in range(c.size(2)):\n",
        "                        l = int(cm.data[0, i, j])\n",
        "                        class_correct[l] += c[0, i, j]\n",
        "                        class_total[l] += 1\n",
        "   \n",
        "                pr = (predicted.int() > 0).cpu().numpy()\n",
        "                gt = (cm.data.int() > 0).cpu().numpy()\n",
        "                \n",
        "                #print(pr.shape)\n",
        "                #print(cm.shape)\n",
        "                #print(xmin,xmax,ymin,ymax)\n",
        "                # Colora l'immagine risultato in base alla predizione\n",
        "\n",
        "                pr=pr[0]\n",
        "                gt=gt[0]\n",
        "\n",
        "                pr_and_gt=np.logical_and(pr, gt)\n",
        "                not_pr_and_not_gt=np.logical_and(np.logical_not(pr), np.logical_not(gt))\n",
        "                pr_and_not_gt=np.logical_and(pr, np.logical_not(gt))\n",
        "                not_pr_and_gt=np.logical_and(np.logical_not(pr), gt)\n",
        "                \n",
        "                tp += pr_and_gt.sum()\n",
        "                tn += not_pr_and_not_gt.sum()\n",
        "                fp +=pr_and_not_gt.sum()\n",
        "                fn += not_pr_and_gt.sum()\n",
        "                \n",
        "              \n",
        "                result_image[xmin:xmax,ymin:ymax][pr_and_gt] = [255, 255, 255]\n",
        "                result_image[xmin:xmax,ymin:ymax][not_pr_and_not_gt] = [0, 0, 0]\n",
        "                result_image[xmin:xmax,ymin:ymax][pr_and_not_gt] = [255, 0, 0]\n",
        "                result_image[xmin:xmax,ymin:ymax][not_pr_and_gt] = [0, 255, 0]\n",
        "                \n",
        "        # Mostra l'immagine risultato\n",
        "        result_image = Image.fromarray(result_image)\n",
        "        result_image.show()\n",
        "        result_image.save(img_index+'.png')\n",
        "\n",
        "    net_loss = tot_loss/tot_count\n",
        "    net_accuracy = 100 * (tp + tn)/tot_count\n",
        "    \n",
        "    for i in range(n):\n",
        "        class_accuracy[i] = 100 * class_correct[i] / max(class_total[i],0.00001)\n",
        "\n",
        "    prec = tp / (tp + fp)\n",
        "    rec = tp / (tp + fn)\n",
        "    f_meas = 2 * prec * rec / (prec + rec)\n",
        "    prec_nc = tn / (tn + fn)\n",
        "    rec_nc = tn / (tn + fp)\n",
        "    \n",
        "    pr_rec = [prec, rec, f_meas, prec_nc, rec_nc]\n",
        "        \n",
        "    return net_loss, net_accuracy, class_accuracy, pr_rec\n",
        "    \n",
        "    \n",
        "if LOAD_TRAINED:\n",
        "    net.load_state_dict(torch.load('net_final.pth.tar'))\n",
        "    print('LOAD OK')\n",
        "else:\n",
        "    t_start = time.time()\n",
        "    out_dic = train()\n",
        "    t_end = time.time()\n",
        "    print(out_dic)\n",
        "    print('Elapsed time:')\n",
        "    print(t_end - t_start)\n",
        "    \n",
        "from google.colab import files\n",
        "\n",
        "for loc in all_locs:\n",
        "  files.download(loc+'.png')\n",
        "  \n",
        "files.download('FC-EF-01-loss.png')\n",
        "files.download('FC-EF-02-accuracy.png')\n",
        "files.download('FC-EF-03-accuracy-per-class.png')\n",
        "files.download('FC-EF-04-prec-rec-fmeas.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LK6LogmLGka5"
      },
      "outputs": [],
      "source": [
        "files.download('FC-EF-04-prec-rec-fmeas.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1QQRwpTvrz_"
      },
      "outputs": [],
      "source": [
        "\n",
        "for loc in all_locs:\n",
        "  files.download(loc+'.png')\n",
        "  \n",
        "files.download('FC-EF-01-loss.png')\n",
        "files.download('FC-EF-02-accuracy.png')\n",
        "files.download('FC-EF-03-accuracy-per-class.png')\n",
        "files.download('FC-EF-04-prec-rec-fmeas.png')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}