{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "file=open(\"./drive/MyDrive/OSCD_dataset/OSCD_dataset_images/train.txt\", \"r\")\n",
        "content = file.read()\n",
        "train_set = content.strip().split(\",\")\n",
        "print(train_set)\n",
        "file.close()\n",
        "\n",
        "file=open(\"./drive/MyDrive/OSCD_dataset/OSCD_dataset_images/test.txt\", \"r\")\n",
        "content = file.read()\n",
        "test_set = content.strip().split(\",\")\n",
        "print(test_set)\n",
        "file.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InYkpqTZmqjn",
        "outputId": "3c62f63f-83db-4e70-aed9-39aae103c414"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['aguasclaras', 'bercy', 'bordeaux', 'nantes', 'paris', 'rennes', 'saclay_e', 'abudhabi', 'cupertino', 'pisa', 'beihai', 'hongkong', 'beirut', 'mumbai']\n",
            "['brasilia', 'montpellier', 'norcia', 'rio', 'saclay_w', 'valencia', 'dubai', 'lasvegas', 'milano', 'chongqing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "img = Image.open('./drive/MyDrive/OSCD_dataset/OSCD_dataset_images/abudhabi/imgs_1_rect/B01.tif')\n",
        "import torch\n",
        "import torchvision.transforms.functional as F\n",
        "tensor=F.to_tensor(img)\n",
        "print(tensor)\n",
        "\n",
        "print(img)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qZt_DMwrFhJ",
        "outputId": "96c7829f-bfa3-4399-c58f-bb3f85ad9712"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[2123, 2115, 2096,  ..., 2368, 2363, 2359],\n",
            "         [2124, 2116, 2097,  ..., 2367, 2363, 2360],\n",
            "         [2127, 2119, 2100,  ..., 2366, 2363, 2360],\n",
            "         ...,\n",
            "         [2255, 2254, 2250,  ..., 2415, 2431, 2440],\n",
            "         [2264, 2262, 2258,  ..., 2407, 2423, 2433],\n",
            "         [2264, 2262, 2258,  ..., 2407, 2423, 2433]]], dtype=torch.int16)\n",
            "<PIL.TiffImagePlugin.TiffImageFile image mode=I;16 size=785x799 at 0x7F5CDC7E3B20>\n"
          ]
        }
      ]
    }
  ]
}